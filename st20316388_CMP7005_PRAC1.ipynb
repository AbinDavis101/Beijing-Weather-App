{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbinDavis101/Beijing-Weather-App/blob/main/st20316388_CMP7005_PRAC1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VewRvtJCXr-",
        "outputId": "bd753cbc-df78-4f88-a03c-3acc1b63e6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfJyb_BFDKq1",
        "outputId": "fce70e57-4a18-4833-be1b-e937d6b2314d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Beijing Air Quality Analysis\",\n",
        "    page_icon=\"üå¨Ô∏è\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "st.title(\"Beijing Air Quality Analysis\")\n",
        "st.markdown(\"\"\"\n",
        "This application analyzes air quality data from various monitoring stations in Beijing, China.\n",
        "The dataset covers the period from March 1st, 2013 to February 28th, 2017 and includes both\n",
        "air pollutants and meteorological conditions.\n",
        "\"\"\")\n",
        "# navigation sidebar\n",
        "st.sidebar.title(\"Navigation\")\n",
        "page = st.sidebar.radio(\"Go to\", [\"Data Overview\", \"Exploratory Data Analysis\", \"Model Evaluation\"])\n",
        "\n",
        "\n",
        "df = pd.read_csv('combined_df.csv')\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "\n",
        "    processed_df = df.copy()\n",
        "\n",
        "\n",
        "\n",
        "    numerical_cols = processed_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    for col in numerical_cols:\n",
        "        processed_df[col] = processed_df[col].fillna(processed_df[col].median())\n",
        "\n",
        "\n",
        "    categorical_cols = processed_df.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        processed_df[col] = processed_df[col].fillna(processed_df[col].mode()[0])\n",
        "\n",
        "\n",
        "    processed_df['datetime'] = pd.to_datetime(processed_df[['year', 'month', 'day', 'hour']])\n",
        "\n",
        "\n",
        "    processed_df['season'] = processed_df['month'].apply(\n",
        "        lambda x: 'Winter' if x in [12, 1, 2] else\n",
        "                  'Spring' if x in [3, 4, 5] else\n",
        "                  'Summer' if x in [6, 7, 8] else 'Autumn'\n",
        "    )\n",
        "\n",
        "\n",
        "    processed_df['wd'] = processed_df['wd'].astype('category')\n",
        "\n",
        "\n",
        "    processed_df = processed_df.drop_duplicates()\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "if df is not None:\n",
        "\n",
        "    processed_df = preprocess_data(df)\n",
        "    # DATA OVERVIEW PAGE\n",
        "    if page == \"Data Overview\":\n",
        "        st.header(\"Data Overview\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"Dataset Information\")\n",
        "            st.write(f\"Number of records: {processed_df.shape[0]}\")\n",
        "            st.write(f\"Number of features: {processed_df.shape[1]}\")\n",
        "            st.write(f\"Time period: {processed_df['datetime'].min()} to {processed_df['datetime'].max()}\")\n",
        "            st.write(f\"Number of stations: {processed_df['station'].nunique()}\")\n",
        "            st.write(\"Stations:\", \", \".join(processed_df['station'].unique()))\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"Data Types\")\n",
        "            st.write(processed_df.dtypes)\n",
        "\n",
        "        st.subheader(\"Sample Data\")\n",
        "        st.dataframe(processed_df.head())\n",
        "\n",
        "        st.subheader(\"Missing Values\")\n",
        "        missing_data = pd.DataFrame({\n",
        "            'Missing Values': processed_df.isnull().sum(),\n",
        "            'Percentage': (processed_df.isnull().sum() / len(processed_df)) * 100\n",
        "        })\n",
        "        st.dataframe(missing_data)\n",
        "\n",
        "        # Visualize missing values\n",
        "        st.subheader(\"Missing Values Visualization\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        sns.heatmap(processed_df.isnull(), yticklabels=False, cbar=False, cmap='viridis', ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        " # EXPLORATORY DATA ANALYSIS PAGE\n",
        "    elif page == \"Exploratory Data Analysis\":\n",
        "        st.header(\"Exploratory Data Analysis\")\n",
        "\n",
        "\n",
        "        st.sidebar.subheader(\"EDA Options\")\n",
        "\n",
        "        eda_choice = st.sidebar.selectbox(\n",
        "            \"Select Analysis Type\",\n",
        "            [\"Univariate Analysis\", \"Bivariate Analysis\", \"Multivariate Analysis\", \"Time Series Analysis\"]\n",
        "        )\n",
        "\n",
        "        if eda_choice == \"Univariate Analysis\":\n",
        "            st.subheader(\"Univariate Analysis\")\n",
        "\n",
        "            variable = st.selectbox(\n",
        "                \"Select Variable\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
        "            )\n",
        "\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.subheader(f\"Distribution of {variable}\")\n",
        "                fig = px.histogram(processed_df, x=variable, nbins=50, marginal=\"box\")\n",
        "                st.plotly_chart(fig)\n",
        "\n",
        "            with col2:\n",
        "                st.subheader(f\"Statistics for {variable}\")\n",
        "                stats = processed_df[variable].describe()\n",
        "                st.dataframe(stats)\n",
        "\n",
        "                st.subheader(f\"Box Plot for {variable}\")\n",
        "                fig = px.box(processed_df, y=variable)\n",
        "                st.plotly_chart(fig)\n",
        "\n",
        "        elif eda_choice == \"Bivariate Analysis\":\n",
        "            st.subheader(\"Bivariate Analysis\")\n",
        "\n",
        "            x_var = st.selectbox(\n",
        "                \"Select X Variable\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM'],\n",
        "                index=0\n",
        "            )\n",
        "\n",
        "            y_var = st.selectbox(\n",
        "                \"Select Y Variable\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM'],\n",
        "                index=1\n",
        "            )\n",
        "\n",
        "            st.subheader(f\"Scatter Plot: {x_var} vs {y_var}\")\n",
        "            fig = px.scatter(processed_df, x=x_var, y=y_var, color='station', opacity=0.6)\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            st.subheader(f\"Correlation between {x_var} and {y_var}\")\n",
        "            corr = processed_df[[x_var, y_var]].corr().iloc[0, 1]\n",
        "            st.write(f\"Correlation coefficient: {corr:.4f}\")\n",
        "\n",
        "            if st.checkbox(\"Show correlation by station\"):\n",
        "                for station in processed_df['station'].unique():\n",
        "                    station_df = processed_df[processed_df['station'] == station]\n",
        "                    corr = station_df[[x_var, y_var]].corr().iloc[0, 1]\n",
        "                    st.write(f\"{station}: {corr:.4f}\")\n",
        "\n",
        "        elif eda_choice == \"Multivariate Analysis\":\n",
        "            st.subheader(\"Multivariate Analysis\")\n",
        "\n",
        "            st.subheader(\"Correlation Matrix\")\n",
        "            corr_vars = st.multiselect(\n",
        "                \"Select Variables for Correlation Matrix\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM'],\n",
        "                default=['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']\n",
        "            )\n",
        "\n",
        "            if corr_vars:\n",
        "                corr_matrix = processed_df[corr_vars].corr()\n",
        "                fig = px.imshow(corr_matrix, text_auto=True, color_continuous_scale='RdBu_r')\n",
        "                st.plotly_chart(fig)\n",
        "\n",
        "            st.subheader(\"Pollutant Analysis by Station\")\n",
        "            selected_pollutant = st.selectbox(\n",
        "                \"Select Pollutant\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']\n",
        "            )\n",
        "\n",
        "            fig = px.box(processed_df, x='station', y=selected_pollutant, color='station')\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            st.subheader(\"Seasonal Analysis\")\n",
        "            selected_season_var = st.selectbox(\n",
        "                \"Select Variable for Seasonal Analysis\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']\n",
        "            )\n",
        "\n",
        "            fig = px.box(processed_df, x='season', y=selected_season_var, color='season')\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "        elif eda_choice == \"Time Series Analysis\":\n",
        "            st.subheader(\"Time Series Analysis\")\n",
        "\n",
        "            # Aggregate by day for better visualization\n",
        "            daily_df = processed_df.groupby([processed_df['datetime'].dt.date, 'station']).agg({\n",
        "                'PM2.5': 'mean',\n",
        "                'PM10': 'mean',\n",
        "                'SO2': 'mean',\n",
        "                'NO2': 'mean',\n",
        "                'CO': 'mean',\n",
        "                'O3': 'mean',\n",
        "                'TEMP': 'mean'\n",
        "            }).reset_index()\n",
        "\n",
        "\n",
        "            daily_df['datetime'] = pd.to_datetime(daily_df['datetime'])\n",
        "\n",
        "            selected_stations = st.multiselect(\n",
        "                \"Select Stations for Time Series\",\n",
        "                processed_df['station'].unique(),\n",
        "                default=[processed_df['station'].unique()[0]]\n",
        "            )\n",
        "\n",
        "            selected_var = st.selectbox(\n",
        "                \"Select Variable for Time Series\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP']\n",
        "            )\n",
        "\n",
        "            # Filter data\n",
        "            filtered_df = daily_df[daily_df['station'].isin(selected_stations)]\n",
        "\n",
        "            # Create time series plot\n",
        "            fig = px.line(filtered_df, x='datetime', y=selected_var, color='station',\n",
        "                          title=f'{selected_var} Over Time')\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # Moving average\n",
        "            if st.checkbox(\"Show moving average\"):\n",
        "                window_size = st.slider(\"Select Window Size (Days)\", 7, 90, 30)\n",
        "\n",
        "                for station in selected_stations:\n",
        "                    station_data = filtered_df[filtered_df['station'] == station].copy()\n",
        "                    station_data[f'{selected_var}_MA'] = station_data[selected_var].rolling(window=window_size).mean()\n",
        "\n",
        "                    fig = px.line(station_data, x='datetime', y=[selected_var, f'{selected_var}_MA'],\n",
        "                                  title=f'{selected_var} with {window_size}-Day Moving Average for {station}')\n",
        "                    st.plotly_chart(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EHj-J4PD9Hm",
        "outputId": "e602297b-181a-40c8-f150-90766c7a638f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.59.187.219\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "itrr1su5D9zE",
        "outputId": "7fde73b7-9355-42cf-9e99-e54b4e9102e1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.59.187.219:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0Kyour url is: https://yummy-wasps-trade.loca.lt\n",
            "2025-05-10 23:09:10.626 Serialization of dataframe to Arrow table was unsuccessful. Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/dataframe_util.py\", line 822, in convert_pandas_df_to_arrow_bytes\n",
            "    table = pa.Table.from_pandas(df)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"pyarrow/table.pxi\", line 4751, in pyarrow.lib.Table.from_pandas\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 625, in dataframe_to_arrays\n",
            "    arrays = [convert_column(c, f)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 625, in <listcomp>\n",
            "    arrays = [convert_column(c, f)\n",
            "              ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 612, in convert_column\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 606, in convert_column\n",
            "    result = pa.array(col, type=type_, from_pandas=True, safe=safe)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"pyarrow/array.pxi\", line 360, in pyarrow.lib.array\n",
            "  File \"pyarrow/array.pxi\", line 87, in pyarrow.lib._ndarray_to_array\n",
            "  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\n",
            "pyarrow.lib.ArrowInvalid: (\"Could not convert dtype('int64') with type numpy.dtypes.Int64DType: did not recognize Python value type when inferring an Arrow data type\", 'Conversion failed for column 0 with type object')\n",
            "/root/.npm/_npx/75ac80b86e83d4a2/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:14289 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/75ac80b86e83d4a2/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (node:events:524:28)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (node:internal/streams/destroy:169:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:128:3)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m\n",
            "\n",
            "Node.js v20.19.0\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA2DjNVTka2QN1m1PQkoZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}