{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbinDavis101/Beijing-Weather-App/blob/main/st20316388_CMP7005_PRAC1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VewRvtJCXr-",
        "outputId": "4619871c-e560-49d9-b449-401986b3592f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.37.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfJyb_BFDKq1",
        "outputId": "e074c48a-adb3-4706-beed-9f0c0fab3f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Beijing Air Quality Analysis\",\n",
        "    page_icon=\"ðŸŒ¬ï¸\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "st.title(\"Beijing Air Quality Analysis\")\n",
        "st.markdown(\"\"\"\n",
        "This application analyzes air quality data from various monitoring stations in Beijing, China.\n",
        "The dataset covers the period from March 1st, 2013 to February 28th, 2017 and includes both\n",
        "air pollutants and meteorological conditions.\n",
        "\"\"\")\n",
        "# navigation sidebar\n",
        "st.sidebar.title(\"Navigation\")\n",
        "page = st.sidebar.radio(\"Go to\", [\"Data Overview\", \"Exploratory Data Analysis\", \"Model Evaluation\"])\n",
        "\n",
        "\n",
        "df = pd.read_csv('combined_df.csv')\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "\n",
        "    processed_df = df.copy()\n",
        "\n",
        "\n",
        "\n",
        "    numerical_cols = processed_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    for col in numerical_cols:\n",
        "        processed_df[col] = processed_df[col].fillna(processed_df[col].median())\n",
        "\n",
        "\n",
        "    categorical_cols = processed_df.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        processed_df[col] = processed_df[col].fillna(processed_df[col].mode()[0])\n",
        "\n",
        "\n",
        "    processed_df['datetime'] = pd.to_datetime(processed_df[['year', 'month', 'day', 'hour']])\n",
        "\n",
        "\n",
        "    processed_df['season'] = processed_df['month'].apply(\n",
        "        lambda x: 'Winter' if x in [12, 1, 2] else\n",
        "                  'Spring' if x in [3, 4, 5] else\n",
        "                  'Summer' if x in [6, 7, 8] else 'Autumn'\n",
        "    )\n",
        "\n",
        "\n",
        "    processed_df['wd'] = processed_df['wd'].astype('category')\n",
        "\n",
        "\n",
        "    processed_df = processed_df.drop_duplicates()\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "# Function for building a model (kept for model evaluation only)\n",
        "def build_model(X_train, X_test, y_train, y_test):\n",
        "          # Scale features\n",
        "          scaler = StandardScaler()\n",
        "          X_train_scaled = scaler.fit_transform(X_train)\n",
        "          X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "         # Define models\n",
        "          models = {\n",
        "              'Linear Regression': LinearRegression(),\n",
        "              'Random Forest': RandomForestRegressor(random_state=42)\n",
        "          }\n",
        "\n",
        "          results = {}\n",
        "          for name, model in models.items():\n",
        "              # Train model\n",
        "              model.fit(X_train_scaled, y_train)\n",
        "\n",
        "             # Make predictions\n",
        "              y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "              # Evaluate\n",
        "              mse = mean_squared_error(y_test, y_pred)\n",
        "              rmse = np.sqrt(mse)\n",
        "              r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "              results[name] = {\n",
        "                  'model': model,\n",
        "                  'mse': mse,\n",
        "                  'rmse': rmse,\n",
        "                  'r2': r2,\n",
        "                  'predictions': y_pred\n",
        "              }\n",
        "\n",
        "\n",
        "          return results\n",
        "\n",
        "if df is not None:\n",
        "\n",
        "    processed_df = preprocess_data(df)\n",
        "    # DATA OVERVIEW PAGE\n",
        "    if page == \"Data Overview\":\n",
        "        st.header(\"Data Overview\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.subheader(\"Dataset Information\")\n",
        "            st.write(f\"Number of records: {processed_df.shape[0]}\")\n",
        "            st.write(f\"Number of features: {processed_df.shape[1]}\")\n",
        "            st.write(f\"Time period: {processed_df['datetime'].min()} to {processed_df['datetime'].max()}\")\n",
        "            st.write(f\"Number of stations: {processed_df['station'].nunique()}\")\n",
        "            st.write(\"Stations:\", \", \".join(processed_df['station'].unique()))\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"Data Types\")\n",
        "            st.write(processed_df.dtypes)\n",
        "\n",
        "        st.subheader(\"Sample Data\")\n",
        "        st.dataframe(processed_df.head())\n",
        "\n",
        "        st.subheader(\"Missing Values\")\n",
        "        missing_data = pd.DataFrame({\n",
        "            'Missing Values': processed_df.isnull().sum(),\n",
        "            'Percentage': (processed_df.isnull().sum() / len(processed_df)) * 100\n",
        "        })\n",
        "        st.dataframe(missing_data)\n",
        "\n",
        "        # Visualize missing values\n",
        "        st.subheader(\"Missing Values Visualization\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        sns.heatmap(processed_df.isnull(), yticklabels=False, cbar=False, cmap='viridis', ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        " # EXPLORATORY DATA ANALYSIS PAGE\n",
        "    elif page == \"Exploratory Data Analysis\":\n",
        "        st.header(\"Exploratory Data Analysis\")\n",
        "\n",
        "\n",
        "        st.sidebar.subheader(\"EDA Options\")\n",
        "\n",
        "        eda_choice = st.sidebar.selectbox(\n",
        "            \"Select Analysis Type\",\n",
        "            [\"Univariate Analysis\", \"Bivariate Analysis\", \"Multivariate Analysis\", \"Time Series Analysis\"]\n",
        "        )\n",
        "\n",
        "        if eda_choice == \"Univariate Analysis\":\n",
        "            st.subheader(\"Univariate Analysis\")\n",
        "\n",
        "            variable = st.selectbox(\n",
        "                \"Select Variable\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
        "            )\n",
        "\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.subheader(f\"Distribution of {variable}\")\n",
        "                fig = px.histogram(processed_df, x=variable, nbins=50, marginal=\"box\")\n",
        "                st.plotly_chart(fig)\n",
        "\n",
        "            with col2:\n",
        "                st.subheader(f\"Statistics for {variable}\")\n",
        "                stats = processed_df[variable].describe()\n",
        "                st.dataframe(stats)\n",
        "\n",
        "                st.subheader(f\"Box Plot for {variable}\")\n",
        "                fig = px.box(processed_df, y=variable)\n",
        "                st.plotly_chart(fig)\n",
        "\n",
        "        elif eda_choice == \"Bivariate Analysis\":\n",
        "            st.subheader(\"Bivariate Analysis\")\n",
        "\n",
        "            x_var = st.selectbox(\n",
        "                \"Select X Variable\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM'],\n",
        "                index=0\n",
        "            )\n",
        "\n",
        "            y_var = st.selectbox(\n",
        "                \"Select Y Variable\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM'],\n",
        "                index=1\n",
        "            )\n",
        "\n",
        "            st.subheader(f\"Scatter Plot: {x_var} vs {y_var}\")\n",
        "            fig = px.scatter(processed_df, x=x_var, y=y_var, color='station', opacity=0.6)\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            st.subheader(f\"Correlation between {x_var} and {y_var}\")\n",
        "            corr = processed_df[[x_var, y_var]].corr().iloc[0, 1]\n",
        "            st.write(f\"Correlation coefficient: {corr:.4f}\")\n",
        "\n",
        "            if st.checkbox(\"Show correlation by station\"):\n",
        "                for station in processed_df['station'].unique():\n",
        "                    station_df = processed_df[processed_df['station'] == station]\n",
        "                    corr = station_df[[x_var, y_var]].corr().iloc[0, 1]\n",
        "                    st.write(f\"{station}: {corr:.4f}\")\n",
        "\n",
        "        elif eda_choice == \"Multivariate Analysis\":\n",
        "            st.subheader(\"Multivariate Analysis\")\n",
        "\n",
        "            st.subheader(\"Correlation Matrix\")\n",
        "            corr_vars = st.multiselect(\n",
        "                \"Select Variables for Correlation Matrix\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM'],\n",
        "                default=['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']\n",
        "            )\n",
        "\n",
        "            if corr_vars:\n",
        "                corr_matrix = processed_df[corr_vars].corr()\n",
        "                fig = px.imshow(corr_matrix, text_auto=True, color_continuous_scale='RdBu_r')\n",
        "                st.plotly_chart(fig)\n",
        "\n",
        "            st.subheader(\"Pollutant Analysis by Station\")\n",
        "            selected_pollutant = st.selectbox(\n",
        "                \"Select Pollutant\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']\n",
        "            )\n",
        "\n",
        "            fig = px.box(processed_df, x='station', y=selected_pollutant, color='station')\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            st.subheader(\"Seasonal Analysis\")\n",
        "            selected_season_var = st.selectbox(\n",
        "                \"Select Variable for Seasonal Analysis\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']\n",
        "            )\n",
        "\n",
        "            fig = px.box(processed_df, x='season', y=selected_season_var, color='season')\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "        elif eda_choice == \"Time Series Analysis\":\n",
        "            st.subheader(\"Time Series Analysis\")\n",
        "\n",
        "            # Aggregate by day for better visualization\n",
        "            daily_df = processed_df.groupby([processed_df['datetime'].dt.date, 'station']).agg({\n",
        "                'PM2.5': 'mean',\n",
        "                'PM10': 'mean',\n",
        "                'SO2': 'mean',\n",
        "                'NO2': 'mean',\n",
        "                'CO': 'mean',\n",
        "                'O3': 'mean',\n",
        "                'TEMP': 'mean'\n",
        "            }).reset_index()\n",
        "\n",
        "\n",
        "            daily_df['datetime'] = pd.to_datetime(daily_df['datetime'])\n",
        "\n",
        "            selected_stations = st.multiselect(\n",
        "                \"Select Stations for Time Series\",\n",
        "                processed_df['station'].unique(),\n",
        "                default=[processed_df['station'].unique()[0]]\n",
        "            )\n",
        "\n",
        "            selected_var = st.selectbox(\n",
        "                \"Select Variable for Time Series\",\n",
        "                ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP']\n",
        "            )\n",
        "\n",
        "            # Filter data\n",
        "            filtered_df = daily_df[daily_df['station'].isin(selected_stations)]\n",
        "\n",
        "            # Create time series plot\n",
        "            fig = px.line(filtered_df, x='datetime', y=selected_var, color='station',\n",
        "                          title=f'{selected_var} Over Time')\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # Moving average\n",
        "            if st.checkbox(\"Show moving average\"):\n",
        "                window_size = st.slider(\"Select Window Size (Days)\", 7, 90, 30)\n",
        "\n",
        "                for station in selected_stations:\n",
        "                    station_data = filtered_df[filtered_df['station'] == station].copy()\n",
        "                    station_data[f'{selected_var}_MA'] = station_data[selected_var].rolling(window=window_size).mean()\n",
        "\n",
        "                    fig = px.line(station_data, x='datetime', y=[selected_var, f'{selected_var}_MA'],\n",
        "                                  title=f'{selected_var} with {window_size}-Day Moving Average for {station}')\n",
        "                    st.plotly_chart(fig)\n",
        "\n",
        "  # MODEL EVALUATION PAGE (renamed \"Modeling and Prediction\")\n",
        "    elif page == \"Model Evaluation\":\n",
        "\n",
        "        st.header(\"Model Evaluation\")\n",
        "\n",
        "\n",
        "        st.sidebar.subheader(\"Model Options\")\n",
        "\n",
        "        target_var = st.sidebar.selectbox(\n",
        "            \"Select Target Variable to Evaluate\",\n",
        "            ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3'],\n",
        "            index=0\n",
        "        )\n",
        "\n",
        "        selected_station = st.sidebar.selectbox(\n",
        "            \"Select Station for Modeling\",\n",
        "            processed_df['station'].unique()\n",
        "        )\n",
        "\n",
        "\n",
        "        station_df = processed_df[processed_df['station'] == selected_station].copy()\n",
        "\n",
        "\n",
        "        feature_options = ['month', 'day', 'hour', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM',\n",
        "                          'SO2', 'NO2', 'CO', 'O3', 'PM2.5', 'PM10']\n",
        "\n",
        "        feature_options.remove(target_var)\n",
        "\n",
        "        selected_features = st.sidebar.multiselect(\n",
        "            \"Select Features for Model\",\n",
        "            feature_options,\n",
        "            default=['month', 'hour', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
        "        )\n",
        "\n",
        "        if st.sidebar.button(\"Evaluate Models\"):\n",
        "            if len(selected_features) > 0:\n",
        "                st.info(\"Evaluating models... This may take a moment.\")\n",
        "\n",
        "                # Prepare data\n",
        "                X = station_df[selected_features]\n",
        "                y = station_df[target_var]\n",
        "\n",
        "                # Split data\n",
        "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                # Build and evaluate models\n",
        "\n",
        "                model_results = build_model(X_train, X_test, y_train, y_test)\n",
        "\n",
        "                # Display results\n",
        "                st.subheader(\"Model Performance\")\n",
        "\n",
        "                results_df = pd.DataFrame({\n",
        "                    'Model': list(model_results.keys()),\n",
        "                    'MSE': [res['mse'] for res in model_results.values()],\n",
        "                    'RMSE': [res['rmse'] for res in model_results.values()],\n",
        "                    'RÂ²': [res['r2'] for res in model_results.values()]\n",
        "                })\n",
        "\n",
        "                st.dataframe(results_df)\n",
        "\n",
        "                # Visualize predictions vs actual for the best model\n",
        "                best_model_name = results_df.iloc[results_df['RÂ²'].argmax()]['Model']\n",
        "                best_model_results = model_results[best_model_name]\n",
        "\n",
        "                st.subheader(f\"Predictions vs Actual ({best_model_name})\")\n",
        "\n",
        "                fig = px.scatter(\n",
        "                    x=y_test, y=best_model_results['predictions'],\n",
        "                    labels={'x': 'Actual', 'y': 'Predicted'},\n",
        "                    title=f\"{best_model_name}: Actual vs Predicted {target_var}\"\n",
        "                )\n",
        "\n",
        "                # Add perfect prediction line\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=[y_test.min(), y_test.max()],\n",
        "                    y=[y_test.min(), y_test.max()],\n",
        "                    mode='lines',\n",
        "                    name='Perfect Prediction',\n",
        "                    line=dict(color='red', dash='dash')\n",
        "                ))\n",
        "\n",
        "                st.plotly_chart(fig)\n",
        "\n",
        "                # Feature importance for Random Forest\n",
        "                if 'Random Forest' in model_results:\n",
        "                    rf_model = model_results['Random Forest']['model']\n",
        "                    feature_importance = pd.DataFrame({\n",
        "                        'Feature': selected_features,\n",
        "                        'Importance': rf_model.feature_importances_\n",
        "                    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "                    st.subheader(\"Feature Importance (Random Forest)\")\n",
        "                    fig = px.bar(feature_importance, x='Feature', y='Importance')\n",
        "                    st.plotly_chart(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EHj-J4PD9Hm",
        "outputId": "13d5c897-219b-4fda-f569-1a0aecdc64d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.59.187.219\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itrr1su5D9zE",
        "outputId": "3d991e70-2587-4260-80ac-b98ff849edb2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.59.187.219:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kyour url is: https://public-mails-feel.loca.lt\n",
            "2025-05-11 00:35:15.803 Serialization of dataframe to Arrow table was unsuccessful. Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/dataframe_util.py\", line 822, in convert_pandas_df_to_arrow_bytes\n",
            "    table = pa.Table.from_pandas(df)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"pyarrow/table.pxi\", line 4751, in pyarrow.lib.Table.from_pandas\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 625, in dataframe_to_arrays\n",
            "    arrays = [convert_column(c, f)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 625, in <listcomp>\n",
            "    arrays = [convert_column(c, f)\n",
            "              ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 612, in convert_column\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/pandas_compat.py\", line 606, in convert_column\n",
            "    result = pa.array(col, type=type_, from_pandas=True, safe=safe)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"pyarrow/array.pxi\", line 360, in pyarrow.lib.array\n",
            "  File \"pyarrow/array.pxi\", line 87, in pyarrow.lib._ndarray_to_array\n",
            "  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\n",
            "pyarrow.lib.ArrowInvalid: (\"Could not convert dtype('int64') with type numpy.dtypes.Int64DType: did not recognize Python value type when inferring an Arrow data type\", 'Conversion failed for column 0 with type object')\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTtyxBagatlWP9oKq8s8+Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}